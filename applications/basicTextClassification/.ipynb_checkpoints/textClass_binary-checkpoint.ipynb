{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is a custom one -> has a few catgories of landscapes. (Replace with any data in folderwise. One for each class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:09:42.093682Z",
     "start_time": "2021-01-20T13:09:42.090482Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from sklearn import model_selection, preprocessing\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer\n",
    "import torchvision.models as models\n",
    "from collections import Counter\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import pickle\n",
    "import os\n",
    "import transformers\n",
    "import pandas as pd\n",
    "os.environ[\"TORCH_HOME\"] = \"~/hdd/Datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsnooper as tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/eragon/hdd/Datasets/moviereview/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_data.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+\"movie_data.csv\", engine = \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie is just crap. Even though the direc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Another detailed work on the subject by Dr Dwi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE CAT O'NINE TAILS (Il Gatto a Nove Code) &lt;b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  This movie is just crap. Even though the direc...          0\n",
       "1  Another detailed work on the subject by Dr Dwi...          1\n",
       "2  THE CAT O'NINE TAILS (Il Gatto a Nove Code) <b...          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49551"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49969, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:11:34.466990Z",
     "start_time": "2021-01-20T13:11:34.459999Z"
    }
   },
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes, num_train_steps, learning_rate=2e-4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # log hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.bert = transformers.BertModel.from_pretrained(\n",
    "            \"bert-base-uncased\" , return_dict = False\n",
    "        )\n",
    "        self.bert_drop = nn.Dropout(.3)\n",
    "        self.out = nn.Linear(768, num_classes)\n",
    "        self.num_train_steps = num_train_steps\n",
    "#         self.er = pl.metrics.Accuracy()\n",
    "        \n",
    "        \n",
    "#     @tp.snoop()\n",
    "    def forward(self, ids, mask , token_type_ids, targets = None):\n",
    "        _, x = self.bert(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
    "        x = self.bert_drop(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "#     @tp.snoop()\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        i,m,to,ta= train_batch['ids'] , train_batch['mask'],train_batch['token_type_ids'], train_batch['targets']\n",
    "        logits = self.forward(i,m,to,ta)\n",
    "        loss = nn.BCEWithLogitsLoss()(logits,ta.view(-1,1))\n",
    "#         print(loss)\n",
    "#         acc = self.er(logits,ta.view(-1,1))\n",
    "#         self.log('train_acc_step', acc)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "#         return acc , loss\n",
    "    \n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        i,m,to,ta= test_batch['ids'] , test_batch['mask'],test_batch['token_type_ids'], test_batch['targets']\n",
    "        logits = self.forward(i,m,to,ta)\n",
    "        loss = nn.BCEWithLogitsLoss()(logits,ta.view(-1,1))\n",
    "#         acc = self.er(logits,ta.view(-1,1))\n",
    "#         self.log('test_acc_step', acc)\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "#         return acc , loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"user\", \"movie\", \"rating\", \"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentiDs:\n",
    "    def __init__(self, texts, targets, max_len = 64):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n",
    "        \"bert-base-uncased\", do_lower_case = False)\n",
    "        self.max_len= max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding = \"max_length\",\n",
    "            truncation = True,\n",
    "        )\n",
    "        \n",
    "        resp = {\n",
    "            \"ids\": torch.tensor(inputs[\"input_ids\"], dtype = torch.long),\n",
    "            \"mask\": torch.tensor(inputs[\"attention_mask\"], dtype = torch.long),\n",
    "            \"token_type_ids\": torch.tensor(inputs[\"token_type_ids\"], dtype = torch.long),\n",
    "            \"targets\": torch.tensor(self.targets[idx], dtype = torch.float),            \n",
    "        }\n",
    "        return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:11:57.734304Z",
     "start_time": "2021-01-20T13:11:57.729146Z"
    }
   },
   "outputs": [],
   "source": [
    "class CSVDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size,data_dir):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # build dataset\n",
    "        df = pd.read_csv(self.data_dir+\"movie_data.csv\", engine = \"python\")\n",
    "        print(df.dtypes)\n",
    "        \n",
    "        # split dataset\n",
    "        self.train, self.test = model_selection.train_test_split(df, test_size = 0.2, random_state = 42, stratify = df.sentiment.values)\n",
    "        print(len(self.train) , len(self.test))\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        md =  SentiDs(self.train.review.values ,self.train.sentiment.values)\n",
    "        return DataLoader(md, batch_size=self.batch_size, shuffle=True, num_workers=12)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        md = SentiDs(self.test.review.values ,self.test.sentiment.values)\n",
    "        return DataLoader(md, batch_size=self.batch_size, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_batch_end(self):\n",
    "    if self.sched is not None:\n",
    "        self.sched.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "batch_size = 64\n",
    "n_train_steps = int(len(df)/batch_size*EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:11:58.135972Z",
     "start_time": "2021-01-20T13:11:58.131286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review       object\n",
      "sentiment     int64\n",
      "dtype: object\n",
      "39975 9994\n"
     ]
    }
   ],
   "source": [
    "dm = CSVDataModule(batch_size=batch_size, data_dir= \"/home/eragon/hdd/Datasets/moviereview/\")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:12:04.659921Z",
     "start_time": "2021-01-20T13:12:04.444379Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LitModel(num_classes = 1 , num_train_steps = n_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:12:17.444559Z",
     "start_time": "2021-01-20T13:12:17.434634Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/eragon/.local/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Disable automatic optimization with the trainer flag is deprecated and will be removed in v1.3.0!Please use the property on the LightningModule for disabling automatic optimization\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(auto_select_gpus=True, gpus=1,\n",
    "                     precision=16, profiler=False,max_epochs=EPOCHS,\n",
    "                    callbacks = [pl.callbacks.ProgressBar()],\n",
    "                     automatic_optimization=True,enable_pl_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:14:35.107768Z",
     "start_time": "2021-01-20T13:12:18.236980Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | bert      | BertModel | 109 M \n",
      "1 | bert_drop | Dropout   | 0     \n",
      "2 | out       | Linear    | 769   \n",
      "----------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57539a9127a74a38bf62fa55c9413ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eragon/.local/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:15:54.893230Z",
     "start_time": "2021-01-20T13:15:54.232722Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281cf0da77134bff9e69a2968cb1daac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.693199098110199}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.693199098110199}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:31:51.888107Z",
     "start_time": "2021-01-20T13:31:51.859261Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trainer.save_checkpoint('model1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load(\"model.ckpt\", device = 'cuda')\n",
    "# preds = model.predict(some_ds , device = \"cuda\")\n",
    "# for p in preds:\n",
    "#     print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
