{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:09:42.093682Z",
     "start_time": "2021-01-20T13:09:42.090482Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import json\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.core.composition import Compose\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn import metrics, model_selection,preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "os.environ[\"TORCH_HOME\"] = \"/media/hdd/Datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsnooper as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at data \n",
    "- Create a csv for easy loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"/media/hdd/Datasets/asl/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/hdd/Datasets/asl/asl_alphabet_train/asl_alphabet_train/V/V1968.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ims = glob.glob(main_path+\"/*/*/*/*.jpg\");all_ims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(x):\n",
    "    return x.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({x:create_label(x) for x in all_ims} ,orient='index').reset_index()\n",
    "df.columns = [\"image_id\",\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/media/hdd/Datasets/asl/asl_alphabet_train/asl...</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/media/hdd/Datasets/asl/asl_alphabet_train/asl...</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/media/hdd/Datasets/asl/asl_alphabet_train/asl...</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/media/hdd/Datasets/asl/asl_alphabet_train/asl...</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/media/hdd/Datasets/asl/asl_alphabet_train/asl...</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id label\n",
       "0  /media/hdd/Datasets/asl/asl_alphabet_train/asl...     V\n",
       "1  /media/hdd/Datasets/asl/asl_alphabet_train/asl...     V\n",
       "2  /media/hdd/Datasets/asl/asl_alphabet_train/asl...     V\n",
       "3  /media/hdd/Datasets/asl/asl_alphabet_train/asl...     V\n",
       "4  /media/hdd/Datasets/asl/asl_alphabet_train/asl...     V"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = preprocessing.LabelEncoder()\n",
    "df['label'] = temp.fit_transform(df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map=  {i: l for i, l in enumerate(temp.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3000\n",
       "15    3000\n",
       "27    3000\n",
       "26    3000\n",
       "25    3000\n",
       "24    3000\n",
       "23    3000\n",
       "22    3000\n",
       "21    3000\n",
       "20    3000\n",
       "19    3000\n",
       "18    3000\n",
       "17    3000\n",
       "16    3000\n",
       "14    3000\n",
       "1     3000\n",
       "13    3000\n",
       "12    3000\n",
       "11    3000\n",
       "10    3000\n",
       "9     3000\n",
       "8     3000\n",
       "7     3000\n",
       "6     3000\n",
       "5     3000\n",
       "4     3000\n",
       "3     3000\n",
       "2     3000\n",
       "28    3000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"kfold\"] = -1\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "stratify = StratifiedKFold(n_splits=5)\n",
    "for i, (t_idx, v_idx) in enumerate(\n",
    "        stratify.split(X=df.image_id.values, y=df.label.values)):\n",
    "    df.loc[v_idx, \"kfold\"] = i\n",
    "    df.to_csv(\"train_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/media/hdd/Datasets/asl/asl_alphabet_train/asl...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_id  label  kfold\n",
       "0  /media/hdd/Datasets/asl/asl_alphabet_train/asl...      6      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"train_folds.csv\").head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:11:34.466990Z",
     "start_time": "2021-01-20T13:11:34.459999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Efficient net b5\n",
    "# @sn.snoop()\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes, learning_rate=1e-4, weight_decay=0.0001):\n",
    "        super().__init__()\n",
    "\n",
    "        # log hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.enet = EfficientNet.from_pretrained('efficientnet-b5',\n",
    "                                                 num_classes=self.num_classes)\n",
    "        in_features = self.enet._fc.in_features\n",
    "        self.enet._fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "#     @sn.snoop()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.enet(x)\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(),\n",
    "                                      lr=self.learning_rate,\n",
    "                                      weight_decay=self.weight_decay)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                    step_size=2,\n",
    "                                                    gamma=0.1)\n",
    "\n",
    "        return ([optimizer], [scheduler])\n",
    "\n",
    "\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch[\"x\"], train_batch[\"y\"]\n",
    "        preds = self(x)\n",
    "        loss = F.cross_entropy(preds, y)\n",
    "        #         loss.requires_grad = True\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log('train_acc_step', acc)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch[\"x\"], val_batch[\"y\"]\n",
    "        preds = self(x)\n",
    "        loss = F.cross_entropy(preds, y)\n",
    "        #         loss.requires_grad = True\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log('val_acc_step', acc)\n",
    "        self.log('val_loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassDs(Dataset):\n",
    "    def __init__(self,\n",
    "                 df: pd.DataFrame,\n",
    "                 imfolder: str,\n",
    "                 train: bool = True,\n",
    "                 transforms=None):\n",
    "        self.df = df\n",
    "        self.imfolder = imfolder\n",
    "        self.train = train\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        im_path = self.df.iloc[index]['image_id']\n",
    "        x = cv2.imread(im_path, cv2.IMREAD_COLOR)\n",
    "        x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if (self.transforms):\n",
    "            x = self.transforms(image=x)['image']\n",
    "\n",
    "        y = self.df.iloc[index]['label']\n",
    "        return {\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:11:57.734304Z",
     "start_time": "2021-01-20T13:11:57.729146Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            df,\n",
    "            batch_size,\n",
    "            num_classes,\n",
    "            data_dir: str = \"/media/hdd/Datasets/asl/\",\n",
    "            img_size=(256, 256)):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.train_transform = A.Compose([\n",
    "            A.RandomResizedCrop(img_size, img_size, p=1.0),\n",
    "            A.Transpose(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.ShiftScaleRotate(p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=0.2,\n",
    "                                 sat_shift_limit=0.2,\n",
    "                                 val_shift_limit=0.2,\n",
    "                                 p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1),\n",
    "                                       contrast_limit=(-0.1, 0.1),\n",
    "                                       p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                        max_pixel_value=255.0,\n",
    "                        p=1.0),\n",
    "            A.CoarseDropout(p=0.5),\n",
    "            A.Cutout(p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "            p=1.)\n",
    "\n",
    "        self.valid_transform = A.Compose([\n",
    "            A.CenterCrop(img_size, img_size, p=1.),\n",
    "            A.Resize(img_size, img_size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                        max_pixel_value=255.0,\n",
    "                        p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "            p=1.)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        dfx = pd.read_csv(\"./train_folds.csv\")\n",
    "        train = dfx.loc[dfx[\"kfold\"] != 1]\n",
    "        val = dfx.loc[dfx[\"kfold\"] == 1]\n",
    "\n",
    "        self.train_dataset = ImageClassDs(train,\n",
    "                                          self.data_dir,\n",
    "                                          train=True,\n",
    "                                          transforms=self.train_transform)\n",
    "\n",
    "        self.valid_dataset = ImageClassDs(val,\n",
    "                                          self.data_dir,\n",
    "                                          train=False,\n",
    "                                          transforms=self.valid_transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=12,\n",
    "                          shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 29\n",
    "img_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:11:58.135972Z",
     "start_time": "2021-01-20T13:11:58.131286Z"
    }
   },
   "outputs": [],
   "source": [
    "dm = ImDataModule(df,\n",
    "                  batch_size=batch_size,\n",
    "                  num_classes=num_classes,\n",
    "                  img_size=img_size)\n",
    "class_ids = dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:12:04.659921Z",
     "start_time": "2021-01-20T13:12:04.444379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "model = LitModel(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = CSVLogger(\"logs\", name=\"eff-b5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:12:17.444559Z",
     "start_time": "2021-01-20T13:12:17.434634Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/eragon/.local/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Disable automatic optimization with the trainer flag is deprecated and will be removed in v1.3.0!Please use the property on the LightningModule for disabling automatic optimization\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Using native 16bit precision.\n",
      "/home/eragon/.local/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: plugin <class 'pytorch_lightning.plugins.sharded_plugin.DDPShardedPlugin'> has added additional required plugins as default: [<class 'pytorch_lightning.plugins.sharded_native_amp_plugin.ShardedNativeAMPPlugin'>]Extend this plugin and override `required_plugins`if this conflicts with your additional plugins.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(auto_select_gpus=True,\n",
    "                     gpus=1,\n",
    "                     precision=16,\n",
    "                     profiler=False,\n",
    "                     max_epochs=5,\n",
    "                     callbacks=[pl.callbacks.ProgressBar()],\n",
    "                     automatic_optimization=True,\n",
    "                     enable_pl_optimizer=True,\n",
    "                     logger=logger,\n",
    "                     accelerator='ddp',\n",
    "                     plugins='ddp_sharded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:14:35.107768Z",
     "start_time": "2021-01-20T13:12:18.236980Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "\n",
      "  | Name | Type         | Params\n",
      "--------------------------------------\n",
      "0 | enet | EfficientNet | 28.4 M\n",
      "--------------------------------------\n",
      "28.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.4 M    Total params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a12f874c6324a76b5f1757d72249841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eragon/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-20T13:31:51.888107Z",
     "start_time": "2021-01-20T13:31:51.859261Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.test()\n",
    "\n",
    "trainer.save_checkpoint('model1.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoints = trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b5\n"
     ]
    }
   ],
   "source": [
    "pre_model = LitModel.load_from_checkpoint(checkpoint_path= best_checkpoints).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model.eval()\n",
    "pre_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "            A.CenterCrop(img_size, img_size, p=1.),\n",
    "            A.Resize(img_size, img_size),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                        max_pixel_value=255.0,\n",
    "                        p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ],\n",
    "            p=1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = transforms(image=cv2.imread(\"/media/hdd/Datasets/asl/asl_alphabet_test/asl_alphabet_test/C_test.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = pre_model(test_img[\"image\"].unsqueeze(0).to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'A',\n",
       " 1: 'B',\n",
       " 2: 'C',\n",
       " 3: 'D',\n",
       " 4: 'E',\n",
       " 5: 'F',\n",
       " 6: 'G',\n",
       " 7: 'H',\n",
       " 8: 'I',\n",
       " 9: 'J',\n",
       " 10: 'K',\n",
       " 11: 'L',\n",
       " 12: 'M',\n",
       " 13: 'N',\n",
       " 14: 'O',\n",
       " 15: 'P',\n",
       " 16: 'Q',\n",
       " 17: 'R',\n",
       " 18: 'S',\n",
       " 19: 'T',\n",
       " 20: 'U',\n",
       " 21: 'V',\n",
       " 22: 'W',\n",
       " 23: 'X',\n",
       " 24: 'Y',\n",
       " 25: 'Z',\n",
       " 26: 'del',\n",
       " 27: 'nothing',\n",
       " 28: 'space'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map[int(torch.argmax(y_hat, dim = 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
