Using custom architecture
Net(
  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=129, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)

\# Unpruned module
\# unpruned params
[('weight', Parameter containing:
tensor([[[[-0.2589,  0.2106, -0.1583],
          [-0.0107,  0.1177,  0.1693],
          [-0.1582, -0.3048, -0.1946]]],


        [[[-0.2546, -0.2522,  0.1571],
          [ 0.1412,  0.1917, -0.0545],
          [ 0.2676,  0.3313,  0.1710]]],


        [[[-0.1841, -0.1318, -0.2144],
          [ 0.2159,  0.0372,  0.3180],
          [-0.0373,  0.2986,  0.1630]]],


        [[[-0.0072, -0.1716,  0.1336],
          [ 0.0185, -0.1685,  0.1939],
          [-0.0510, -0.3221, -0.1861]]],


        [[[ 0.3024,  0.1376, -0.2247],
          [ 0.2601,  0.0108, -0.3094],
          [ 0.0984, -0.1046, -0.1212]]],


        [[[ 0.0174, -0.3036,  0.0082],
          [ 0.2701,  0.0659, -0.0367],
          [ 0.1519, -0.0292, -0.1074]]]], device='cuda:0', requires_grad=True)), ('bias', Parameter containing:
tensor([ 0.0808,  0.0353,  0.1264, -0.0875,  0.2702,  0.2237], device='cuda:0',
       requires_grad=True))]
\# Unpruned buffers
[]
# Prune a single module (here conv1) by 30%
# conv1 pruned params
[('bias', Parameter containing:
tensor([ 0.0808,  0.0353,  0.1264, -0.0875,  0.2702,  0.2237], device='cuda:0',
       requires_grad=True)), ('weight_orig', Parameter containing:
tensor([[[[-0.2589,  0.2106, -0.1583],
          [-0.0107,  0.1177,  0.1693],
          [-0.1582, -0.3048, -0.1946]]],


        [[[-0.2546, -0.2522,  0.1571],
          [ 0.1412,  0.1917, -0.0545],
          [ 0.2676,  0.3313,  0.1710]]],


        [[[-0.1841, -0.1318, -0.2144],
          [ 0.2159,  0.0372,  0.3180],
          [-0.0373,  0.2986,  0.1630]]],


        [[[-0.0072, -0.1716,  0.1336],
          [ 0.0185, -0.1685,  0.1939],
          [-0.0510, -0.3221, -0.1861]]],


        [[[ 0.3024,  0.1376, -0.2247],
          [ 0.2601,  0.0108, -0.3094],
          [ 0.0984, -0.1046, -0.1212]]],


        [[[ 0.0174, -0.3036,  0.0082],
          [ 0.2701,  0.0659, -0.0367],
          [ 0.1519, -0.0292, -0.1074]]]], device='cuda:0', requires_grad=True))]
# conv1 pruned buffers
[('weight_mask', tensor([[[[1., 1., 0.],
          [1., 1., 0.],
          [1., 1., 1.]]],


        [[[1., 1., 1.],
          [1., 1., 1.],
          [0., 1., 0.]]],


        [[[0., 0., 1.],
          [1., 0., 1.],
          [1., 1., 1.]]],


        [[[0., 0., 1.],
          [1., 1., 1.],
          [0., 1., 1.]]],


        [[[1., 1., 1.],
          [1., 0., 1.],
          [1., 0., 1.]]],


        [[[1., 1., 0.],
          [1., 1., 0.],
          [0., 0., 1.]]]], device='cuda:0'))]
# conv1 pruned bias params
[('weight_orig', Parameter containing:
tensor([[[[-0.2589,  0.2106, -0.1583],
          [-0.0107,  0.1177,  0.1693],
          [-0.1582, -0.3048, -0.1946]]],


        [[[-0.2546, -0.2522,  0.1571],
          [ 0.1412,  0.1917, -0.0545],
          [ 0.2676,  0.3313,  0.1710]]],


        [[[-0.1841, -0.1318, -0.2144],
          [ 0.2159,  0.0372,  0.3180],
          [-0.0373,  0.2986,  0.1630]]],


        [[[-0.0072, -0.1716,  0.1336],
          [ 0.0185, -0.1685,  0.1939],
          [-0.0510, -0.3221, -0.1861]]],


        [[[ 0.3024,  0.1376, -0.2247],
          [ 0.2601,  0.0108, -0.3094],
          [ 0.0984, -0.1046, -0.1212]]],


        [[[ 0.0174, -0.3036,  0.0082],
          [ 0.2701,  0.0659, -0.0367],
          [ 0.1519, -0.0292, -0.1074]]]], device='cuda:0', requires_grad=True)), ('bias_orig', Parameter containing:
tensor([ 0.0808,  0.0353,  0.1264, -0.0875,  0.2702,  0.2237], device='cuda:0',
       requires_grad=True))]
# conv1 pruned bias buffers
[('weight_mask', tensor([[[[1., 1., 0.],
          [1., 1., 0.],
          [1., 1., 1.]]],


        [[[1., 1., 1.],
          [1., 1., 1.],
          [0., 1., 0.]]],


        [[[0., 0., 1.],
          [1., 0., 1.],
          [1., 1., 1.]]],


        [[[0., 0., 1.],
          [1., 1., 1.],
          [0., 1., 1.]]],


        [[[1., 1., 1.],
          [1., 0., 1.],
          [1., 0., 1.]]],


        [[[1., 1., 0.],
          [1., 1., 0.],
          [0., 0., 1.]]]], device='cuda:0')), ('bias_mask', tensor([0., 0., 1., 0., 1., 1.], device='cuda:0'))]
# Forward pre hooks
OrderedDict([(0, <torch.nn.utils.prune.RandomUnstructured object at 0x7fafc6b94b38>), (1, <torch.nn.utils.prune.L1Unstructured object at 0x7faf5d0d0b70>)])
tensor([[[[-0.0000,  0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000]]],


        [[[-0.2546, -0.2522,  0.1571],
          [ 0.1412,  0.1917, -0.0545],
          [ 0.0000,  0.3313,  0.0000]]],


        [[[-0.0000, -0.0000, -0.2144],
          [ 0.2159,  0.0000,  0.3180],
          [-0.0373,  0.2986,  0.1630]]],


        [[[-0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000]]],


        [[[ 0.3024,  0.1376, -0.2247],
          [ 0.2601,  0.0000, -0.3094],
          [ 0.0984, -0.0000, -0.1212]]],


        [[[ 0.0000, -0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.0000],
          [ 0.0000, -0.0000, -0.0000]]]], device='cuda:0',
       grad_fn=<MulBackward0>)
[<torch.nn.utils.prune.RandomUnstructured object at 0x7fafc6b94b38>, <torch.nn.utils.prune.LnStructured object at 0x7faf5d0d0e10>]
[('bias_orig', Parameter containing:
tensor([ 0.0808,  0.0353,  0.1264, -0.0875,  0.2702,  0.2237], device='cuda:0',
       requires_grad=True)), ('weight', Parameter containing:
tensor([[[[-0.0000,  0.0000, -0.0000],
          [-0.0000,  0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000]]],


        [[[-0.2546, -0.2522,  0.1571],
          [ 0.1412,  0.1917, -0.0545],
          [ 0.0000,  0.3313,  0.0000]]],


        [[[-0.0000, -0.0000, -0.2144],
          [ 0.2159,  0.0000,  0.3180],
          [-0.0373,  0.2986,  0.1630]]],


        [[[-0.0000, -0.0000,  0.0000],
          [ 0.0000, -0.0000,  0.0000],
          [-0.0000, -0.0000, -0.0000]]],


        [[[ 0.3024,  0.1376, -0.2247],
          [ 0.2601,  0.0000, -0.3094],
          [ 0.0984, -0.0000, -0.1212]]],


        [[[ 0.0000, -0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.0000],
          [ 0.0000, -0.0000, -0.0000]]]], device='cuda:0', requires_grad=True))]
dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])
global sparsity: 20.00%
